{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_ROOT = 'raw'\n",
    "DATA_ROOT = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_raw, df_item_raw, df_log_raw, df_sub_raw = utils.load_raw(RAW_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_user_raw.copy()\n",
    "\n",
    "df_user['FN'].fillna(0, inplace=True)\n",
    "df_user['Active'].fillna(0, inplace=True)\n",
    "df_user['club_member_status'].fillna('NONE', inplace=True)\n",
    "df_user['fashion_news_frequency'].fillna('NONE', inplace=True)\n",
    "df_user.loc[df_user['fashion_news_frequency'] == 'None', 'fashion_news_frequency'] = 'NONE'\n",
    "\n",
    "df_user.set_index('customer_id', inplace=True)\n",
    "\n",
    "df_user = df_user.astype({\n",
    "    'FN': int,\n",
    "    'Active': int,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'postal_code' in df_user.columns:\n",
    "    df_user = df_user.drop(columns=['postal_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_member = pd.get_dummies(df_user['club_member_status']).drop('NONE', axis=1)\n",
    "oh_newsfreq = pd.get_dummies(df_user['fashion_news_frequency'])\n",
    "\n",
    "df_user = df_user.drop('club_member_status', axis=1).drop('fashion_news_frequency', axis=1)\n",
    "df_user = df_user.join(oh_member).join(oh_newsfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.loc[df_user['age'].isna(), 'age'] = round(df_user.loc[df_user['age'].notnull(), 'age'].mean())\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gm = GaussianMixture(n_components=2).fit(df_user['age'].values.reshape(-1, 1))\n",
    "mu1, mu2 = gm.means_.flatten()\n",
    "var1, var2 = gm.covariances_.flatten()\n",
    "sigma1, sigma2 = np.sqrt(var1), np.sqrt(var2)\n",
    "del gm\n",
    "df_user['age_gmm_1'] = (df_user['age'] - mu1) / sigma1\n",
    "df_user['age_gmm_2'] = (df_user['age'] - mu2) / sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>Active</th>\n",
       "      <th>age</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>LEFT CLUB</th>\n",
       "      <th>PRE-CREATE</th>\n",
       "      <th>Monthly</th>\n",
       "      <th>NONE</th>\n",
       "      <th>Regularly</th>\n",
       "      <th>age_gmm_1</th>\n",
       "      <th>age_gmm_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.035845</td>\n",
       "      <td>4.973913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000423b00ade91418cceaf3b26c6af3dd342b51fd051eec9c12fb36984420fa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.415854</td>\n",
       "      <td>-0.068474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.515021</td>\n",
       "      <td>-0.278574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2c5feb1ca5dff07c43e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459991</td>\n",
       "      <td>6.024411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801fe7fc0f26dd8d65a85a</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261657</td>\n",
       "      <td>5.604212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    FN  Active   age  ACTIVE  \\\n",
       "customer_id                                                                    \n",
       "00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d...   0       0  49.0       1   \n",
       "0000423b00ade91418cceaf3b26c6af3dd342b51fd051ee...   0       0  25.0       1   \n",
       "000058a12d5b43e67d225668fa1f8d618c13dc232df0cad...   0       0  24.0       1   \n",
       "00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2c...   0       0  54.0       1   \n",
       "00006413d8573cd20ed7128e53b7b13819fe5cfc2d801fe...   1       1  52.0       1   \n",
       "\n",
       "                                                    LEFT CLUB  PRE-CREATE  \\\n",
       "customer_id                                                                 \n",
       "00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d...          0           0   \n",
       "0000423b00ade91418cceaf3b26c6af3dd342b51fd051ee...          0           0   \n",
       "000058a12d5b43e67d225668fa1f8d618c13dc232df0cad...          0           0   \n",
       "00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2c...          0           0   \n",
       "00006413d8573cd20ed7128e53b7b13819fe5cfc2d801fe...          0           0   \n",
       "\n",
       "                                                    Monthly  NONE  Regularly  \\\n",
       "customer_id                                                                    \n",
       "00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d...        0     1          0   \n",
       "0000423b00ade91418cceaf3b26c6af3dd342b51fd051ee...        0     1          0   \n",
       "000058a12d5b43e67d225668fa1f8d618c13dc232df0cad...        0     1          0   \n",
       "00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2c...        0     1          0   \n",
       "00006413d8573cd20ed7128e53b7b13819fe5cfc2d801fe...        0     0          1   \n",
       "\n",
       "                                                    age_gmm_1  age_gmm_2  \n",
       "customer_id                                                               \n",
       "00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d...  -0.035845   4.973913  \n",
       "0000423b00ade91418cceaf3b26c6af3dd342b51fd051ee...  -2.415854  -0.068474  \n",
       "000058a12d5b43e67d225668fa1f8d618c13dc232df0cad...  -2.515021  -0.278574  \n",
       "00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2c...   0.459991   6.024411  \n",
       "00006413d8573cd20ed7128e53b7b13819fe5cfc2d801fe...   0.261657   5.604212  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.to_parquet(f'{DATA_ROOT}/df_user_preprocessed.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = df_log_raw.copy()\n",
    "\n",
    "dts_to_dto_map = {}\n",
    "dts_to_ts_map = {}\n",
    "for dts in df_log_raw['t_dat'].unique():\n",
    "    dto = dt.strptime(dts, '%Y-%m-%d')\n",
    "    dts_to_dto_map[dts] = dto\n",
    "    dts_to_ts_map[dts] = int(dto.timestamp())\n",
    "\n",
    "df_log['timestamp'] = df_log_raw['t_dat'].map(dts_to_ts_map)\n",
    "df_log['dto'] = df_log_raw['t_dat'].map(dts_to_dto_map)\n",
    "\n",
    "df_log['week'] = 104 - (df_log['dto'].max() - df_log['dto']).dt.days // 7\n",
    "\n",
    "log_price = np.log(df_log['price'])\n",
    "mu = log_price.mean()\n",
    "sigma = log_price.std()\n",
    "df_log['log_price'] = (log_price - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>dto</th>\n",
       "      <th>week</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0663713001</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>2</td>\n",
       "      <td>1537369200</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.231676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0541518023</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>2</td>\n",
       "      <td>1537369200</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0505221004</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>2</td>\n",
       "      <td>1537369200</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.619252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687003</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "      <td>1537369200</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.457210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687004</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "      <td>1537369200</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.457210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat                                        customer_id  article_id  \\\n",
       "0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0663713001   \n",
       "1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0541518023   \n",
       "2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0505221004   \n",
       "3  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687003   \n",
       "4  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687004   \n",
       "\n",
       "      price  sales_channel_id   timestamp        dto  week  log_price  \n",
       "0  0.050831                 2  1537369200 2018-09-20     0   1.231676  \n",
       "1  0.030492                 2  1537369200 2018-09-20     0   0.446524  \n",
       "2  0.015237                 2  1537369200 2018-09-20     0  -0.619252  \n",
       "3  0.016932                 2  1537369200 2018-09-20     0  -0.457210  \n",
       "4  0.016932                 2  1537369200 2018-09-20     0  -0.457210  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log.to_parquet(f'{DATA_ROOT}/df_log_preprocessed.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = df_item_raw.copy()\n",
    "\n",
    "df_item.set_index('article_id', inplace=True)\n",
    "\n",
    "product_group_name_map = {}\n",
    "for index, name in enumerate(list(df_item['product_group_name'].unique())):\n",
    "    product_group_name_map[name] = index\n",
    "product_group_name_map['Unknown'] = -1\n",
    "\n",
    "df_item['product_group_no'] = df_item['product_group_name'].map(product_group_name_map)\n",
    "\n",
    "field_pairs = [\n",
    "    ('product_type_no', 'product_type_name'),\n",
    "    ('graphical_appearance_no', 'graphical_appearance_name'),\n",
    "    ('colour_group_code', 'colour_group_name'),\n",
    "    ('perceived_colour_value_id', 'perceived_colour_value_name'),\n",
    "    ('perceived_colour_master_id', 'perceived_colour_master_name'),\n",
    "    ('department_no', 'department_name'),\n",
    "    ('index_code', 'index_name'),\n",
    "    ('index_group_no', 'index_group_name'),\n",
    "    ('section_no', 'section_name'),\n",
    "    ('garment_group_no', 'garment_group_name'),\n",
    "]\n",
    "\n",
    "os.makedirs(f'{DATA_ROOT}/meta', exist_ok=True)\n",
    "for pair in field_pairs:\n",
    "    pair_name = '_'.join(pair[0].split('_')[:-1])\n",
    "    rows = df_item.groupby(list(pair)).size().reset_index().values\n",
    "    number2name = {}\n",
    "    for row in rows:\n",
    "        number, name, _ = row\n",
    "        number = str(number)\n",
    "        number2name[number] = name\n",
    "    with open(f'{DATA_ROOT}/meta/map_{pair_name}.pkl', 'wb') as fp:\n",
    "        pickle.dump(number2name, fp)\n",
    "\n",
    "fields_with_unknown = [\n",
    "    'product_type_no',\n",
    "    'graphical_appearance_no',\n",
    "    'colour_group_code',\n",
    "    'perceived_colour_value_id',\n",
    "    'perceived_colour_master_id',\n",
    "    'garment_group_no',\n",
    "]\n",
    "\n",
    "df_item.loc[df_item['garment_group_no'] == 1001, 'garment_group_no'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 1.68개의 조건을 제거했어야했음 (표준편차: 1.32)\n"
     ]
    }
   ],
   "source": [
    "iids = df_item.index.to_list()\n",
    "iids_with_no_desc = df_item[df_item['detail_desc'].isna()].index.to_list()\n",
    "\n",
    "ss_item_count = df_log_raw.groupby('article_id')['customer_id'].count()\n",
    "ss_item_count.name = 'transaction_count'\n",
    "\n",
    "df_item_yes_desc = df_item[~df_item['detail_desc'].isna()]\n",
    "df_item_yes_desc = df_item_yes_desc.merge(ss_item_count, how='left', left_index=True, right_index=True)\n",
    "df_item_yes_desc['transaction_count'].fillna(0, inplace=True)\n",
    "\n",
    "most_popular_desc = df_item_yes_desc.sort_values('transaction_count').iloc[-1].detail_desc\n",
    "\n",
    "similar_condition_fields = [\n",
    "    'garment_group_no',\n",
    "    'product_group_no',\n",
    "    'perceived_colour_master_id',\n",
    "    'product_type_no',\n",
    "    'section_no',\n",
    "    'index_code',\n",
    "    'perceived_colour_value_id',\n",
    "    'colour_group_code',\n",
    "    'graphical_appearance_no',\n",
    "    'department_no',\n",
    "    'product_code',\n",
    "]\n",
    "\n",
    "trials = []\n",
    "for iid in iids_with_no_desc:\n",
    "    row = df_item.loc[iid]\n",
    "    desc = most_popular_desc\n",
    "    for i in range(len(similar_condition_fields) - 1):\n",
    "        cut = len(similar_condition_fields) - i\n",
    "        fields = [field for field in similar_condition_fields[:cut] if row[field] != -1]\n",
    "        cond = (df_item_yes_desc[fields[0]] == row[fields[0]])\n",
    "        for j in range(1, len(fields)):\n",
    "            field = fields[j]\n",
    "            cond = cond & (df_item_yes_desc[field] == row[field])\n",
    "        df_item_candidates = df_item_yes_desc[cond]\n",
    "        count = len(df_item_candidates)\n",
    "        if count:\n",
    "            desc = df_item_candidates.sort_values('transaction_count').iloc[-1]['detail_desc']\n",
    "            trials.append(i)\n",
    "            break\n",
    "    df_item.loc[iid, 'detail_desc'] = desc\n",
    "trials = np.array(trials)\n",
    "print(f\"평균 {trials.mean():.02f}개의 조건을 제거했어야했음 (표준편차: {trials.std():.02f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.drop(columns=[\n",
    "    'product_type_name',\n",
    "    'product_group_name',\n",
    "    'graphical_appearance_name',\n",
    "    'colour_group_name',\n",
    "    'perceived_colour_value_name',\n",
    "    'perceived_colour_master_name',\n",
    "    'department_name',\n",
    "    'index_name',\n",
    "    'index_group_name',\n",
    "    'section_name',\n",
    "    'garment_group_name',\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.to_parquet(f'{DATA_ROOT}/df_item_preprocessed.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_parquet(f'{DATA_ROOT}/df_user_preprocessed.pq')\n",
    "df_item = pd.read_parquet(f'{DATA_ROOT}/df_item_preprocessed.pq')\n",
    "df_log_all = pd.read_parquet(f'{DATA_ROOT}/df_log_preprocessed.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAME = 'CV'\n",
    "\n",
    "df_log = utils.get_df_log_of(df_log_all, DNAME)\n",
    "df_log = df_log[df_log['target'] != 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_log_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel_count = df_log['sales_channel_id'].value_counts()\n",
    "global_online_prob = df_channel_count.loc[2] / (df_channel_count.loc[2] + df_channel_count.loc[1])\n",
    "\n",
    "ss_sc_online_count = df_log[df_log['sales_channel_id'] == 2].groupby('customer_id').size()\n",
    "ss_sc_offline_count = df_log[df_log['sales_channel_id'] == 1].groupby('customer_id').size()\n",
    "\n",
    "df_user['online_prob'] = ss_sc_online_count / (ss_sc_online_count + ss_sc_offline_count)\n",
    "\n",
    "del ss_sc_online_count\n",
    "del ss_sc_offline_count\n",
    "\n",
    "df_user['online_prob'].fillna(global_online_prob, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_with_cohort_group = df_item.copy()\n",
    "\n",
    "df_item_with_cohort_group['cohort_group'] = df_item_with_cohort_group['index_code'].copy()\n",
    "\n",
    "df_log_with_cohort_group = df_log.merge(df_item_with_cohort_group['cohort_group'], how='left', left_on='article_id', right_index=True)\n",
    "\n",
    "del df_item_with_cohort_group\n",
    "\n",
    "cohort_group_columns = ['A', 'B', 'C', 'D', 'F', 'G', 'H', 'I', 'J', 'S']\n",
    "df_user_of_cohort_group_counts = df_log_with_cohort_group[['customer_id', 'article_id', 'cohort_group']].groupby(['customer_id', 'cohort_group']).count().unstack()\n",
    "df_user_of_cohort_group_counts.fillna(0, inplace=True)\n",
    "df_user_of_cohort_group_counts.columns = cohort_group_columns\n",
    "\n",
    "df_cohort_count = df_log_with_cohort_group['cohort_group'].value_counts()\n",
    "df_cohort_dist = df_cohort_count.copy()\n",
    "df_cohort_dist = df_cohort_dist / df_cohort_dist.sum()\n",
    "\n",
    "del df_log_with_cohort_group\n",
    "\n",
    "df_user_of_cohort_group_dist = df_user_of_cohort_group_counts.div(df_user_of_cohort_group_counts.sum(1), axis='index')\n",
    "df_user_of_cohort_group_dist.columns = [f'cohort_prob_{code}' for code in cohort_group_columns]\n",
    "df_user = df_user.merge(df_user_of_cohort_group_dist, how='left', left_index=True, right_index=True)\n",
    "\n",
    "del df_user_of_cohort_group_dist\n",
    "del df_user_of_cohort_group_counts\n",
    "\n",
    "for code in cohort_group_columns:\n",
    "    df_user[f'cohort_prob_{code}'].fillna(df_cohort_dist.loc[code], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_with_garment_group = df_item.copy()\n",
    "\n",
    "df_item_with_garment_group['garment_group'] = df_item_with_garment_group['garment_group_no'].copy()\n",
    "df_item_with_garment_group = df_item_with_garment_group[df_item_with_garment_group['garment_group'] != -1]\n",
    "\n",
    "df_log_with_garment_group = df_log.merge(df_item_with_garment_group['garment_group'], how='inner', left_on='article_id', right_index=True)\n",
    "df_log_with_garment_group = df_log_with_garment_group.astype({\n",
    "    'garment_group': int,\n",
    "})\n",
    "\n",
    "del df_item_with_garment_group\n",
    "\n",
    "df_garment_count = df_log_with_garment_group['garment_group'].value_counts()\n",
    "df_garment_dist = df_garment_count.copy()\n",
    "df_garment_dist = df_garment_dist / df_garment_dist.sum()\n",
    "\n",
    "df_user_of_garment_group_counts = df_log_with_garment_group[['customer_id', 'article_id', 'garment_group']].groupby(['customer_id', 'garment_group']).count().unstack()\n",
    "df_user_of_garment_group_counts.fillna(0, inplace=True)\n",
    "df_user_of_garment_group_counts.columns = [f'garment_prob_{garment_group}' for _, garment_group in df_user_of_garment_group_counts.columns.to_list()]\n",
    "\n",
    "del df_log_with_garment_group\n",
    "\n",
    "df_user_of_garment_group_dist = df_user_of_garment_group_counts.div(df_user_of_garment_group_counts.sum(1), axis='index')\n",
    "df_user = df_user.merge(df_user_of_garment_group_dist, how='left', left_index=True, right_index=True)\n",
    "\n",
    "del df_user_of_garment_group_dist\n",
    "del df_user_of_garment_group_counts\n",
    "\n",
    "for index in df_garment_dist.index.to_list():\n",
    "    df_user[f'garment_prob_{index}'].fillna(df_garment_dist.loc[index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_of_avg_price = df_log.groupby('customer_id')['price'].mean('price')\n",
    "df_user_of_avg_price.name = 'avg_price'\n",
    "\n",
    "global_avg_price = df_log['price'].mean()\n",
    "\n",
    "df_user = df_user.merge(df_user_of_avg_price, how='left', left_index=True, right_index=True)\n",
    "df_user['avg_price'].fillna(global_avg_price, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_transaction_count = df_log.groupby('customer_id').size()\n",
    "ss_transaction_count.name = 'transaction_count'\n",
    "\n",
    "df_user = df_user.merge(ss_transaction_count, how='left', left_index=True, right_index=True)\n",
    "df_user['transaction_count'].fillna(0, inplace=True)\n",
    "\n",
    "del ss_transaction_count\n",
    "\n",
    "cold_threshold = int(np.percentile(df_user['transaction_count'], 50))\n",
    "df_user['is_cold'] = 0\n",
    "df_user.loc[df_user['transaction_count'] < cold_threshold, 'is_cold'] = 1\n",
    "\n",
    "df_user['is_new'] = 0\n",
    "df_user.loc[df_user['transaction_count'] < 1, 'is_new'] = 1\n",
    "\n",
    "df_user['log_transaction_count'] = np.log(1 + df_user['transaction_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_of_week = df_log.groupby('customer_id').aggregate({'week': 'max'})\n",
    "df_user_of_week.columns = ['last_active_week']\n",
    "\n",
    "df_user = df_user.merge(df_user_of_week, how='left', left_index=True, right_index=True)\n",
    "df_user['last_active_week'].fillna(0, inplace=True)\n",
    "df_user = df_user.astype({\n",
    "    'last_active_week': int,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.to_parquet(f'{DATA_ROOT}/df_user_aggregated_{DNAME}.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_user\n",
    "del df_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregate item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = pd.read_parquet(f'{DATA_ROOT}/df_item_preprocessed.pq')\n",
    "df_log_all = pd.read_parquet(f'{DATA_ROOT}/df_log_preprocessed.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAME = 'CV'\n",
    "\n",
    "df_log = utils.get_df_log_of(df_log_all, DNAME)\n",
    "df_log = df_log[df_log['target'] != 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_log_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel_count = df_log['sales_channel_id'].value_counts()\n",
    "\n",
    "global_online_prob = df_channel_count.loc[2] / (df_channel_count.loc[2] + df_channel_count.loc[1])\n",
    "\n",
    "ss_sc_online_count = df_log[df_log['sales_channel_id'] == 2].groupby('article_id').size()\n",
    "ss_sc_offline_count = df_log[df_log['sales_channel_id'] == 1].groupby('article_id').size()\n",
    "\n",
    "df_item['online_prob'] = ss_sc_online_count / (ss_sc_online_count + ss_sc_offline_count)\n",
    "\n",
    "del ss_sc_online_count\n",
    "del ss_sc_offline_count\n",
    "\n",
    "df_item['online_prob'].fillna(global_online_prob, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_of_avg_price = df_log.groupby('article_id')['price'].mean('price')\n",
    "df_item_of_avg_price.name = 'avg_price'\n",
    "\n",
    "global_avg_price = df_log['price'].mean()\n",
    "\n",
    "df_item = df_item.merge(df_item_of_avg_price, how='left', left_index=True, right_index=True)\n",
    "df_item['avg_price'].fillna(global_avg_price, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "month2season = {\n",
    "    1: 'winter',\n",
    "    2: 'winter',\n",
    "    3: 'spring',\n",
    "    4: 'spring',\n",
    "    5: 'spring',\n",
    "    6: 'summer',\n",
    "    7: 'summer',\n",
    "    8: 'summer',\n",
    "    9: 'fall',\n",
    "    10: 'fall',\n",
    "    11: 'fall',\n",
    "    12: 'winter',\n",
    "}\n",
    "\n",
    "dts_to_season_map = {}\n",
    "for dts in df_log['t_dat'].unique():\n",
    "    month = int(dts.split('-')[1])\n",
    "    season = month2season[month]\n",
    "    dts_to_season_map[dts] = season\n",
    "\n",
    "df_log['season'] = df_log['t_dat'].map(dts_to_season_map)\n",
    "\n",
    "season_to_count_map = df_log['season'].value_counts().sort_values(ascending=False).to_dict()\n",
    "\n",
    "df_season_count = df_log['season'].value_counts()\n",
    "df_season_dist = df_season_count.copy()\n",
    "df_season_dist = df_season_dist / df_season_dist.sum()\n",
    "\n",
    "df_item_of_season_counts = df_log[['customer_id', 'article_id', 'season']].groupby(['article_id', 'season']).count().unstack()\n",
    "df_item_of_season_counts.fillna(0, inplace=True)\n",
    "df_item_of_season_counts.columns = [f'season_prob_{season}' for _, season in df_item_of_season_counts.columns.to_list()]\n",
    "\n",
    "df_item_of_season_dist = df_item_of_season_counts.div(df_item_of_season_counts.sum(1), axis='index')\n",
    "df_item = df_item.merge(df_item_of_season_dist, how='left', left_index=True, right_index=True)\n",
    "\n",
    "del df_item_of_season_counts\n",
    "del df_item_of_season_dist\n",
    "\n",
    "for index in df_season_dist.index.to_list():\n",
    "    df_item[f'season_prob_{index}'].fillna(df_season_dist.loc[index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_transaction_count = df_log.groupby('article_id').size()\n",
    "ss_transaction_count.name = 'transaction_count'\n",
    "\n",
    "df_item = df_item.merge(ss_transaction_count, how='left', left_index=True, right_index=True)\n",
    "df_item['transaction_count'].fillna(0, inplace=True)\n",
    "\n",
    "del ss_transaction_count\n",
    "\n",
    "cold_threshold = int(np.percentile(df_item['transaction_count'], 50))\n",
    "df_item['is_cold'] = 0\n",
    "df_item.loc[df_item['transaction_count'] < cold_threshold, 'is_cold'] = 1\n",
    "\n",
    "df_item['is_new'] = 0\n",
    "df_item.loc[df_item['transaction_count'] < 1, 'is_new'] = 1\n",
    "\n",
    "df_item['log_transaction_count'] = np.log(1 + df_item['transaction_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.to_parquet(f'{DATA_ROOT}/df_item_aggregated_{DNAME}.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_item\n",
    "del df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_user_raw\n",
    "del df_item_raw\n",
    "del df_log_raw\n",
    "del df_sub_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAME = 'CV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_parquet(f'{DATA_ROOT}/df_user_aggregated_{DNAME}.pq')\n",
    "\n",
    "df_user_feature = df_user.copy()\n",
    "del df_user\n",
    "\n",
    "df_user_feature.drop(columns=[\n",
    "    'age',\n",
    "    'transaction_count',\n",
    "], inplace=True)\n",
    "\n",
    "one_hot_fields = [\n",
    "    'FN',\n",
    "    'Active',\n",
    "    'is_cold',\n",
    "]\n",
    "for field in one_hot_fields:\n",
    "    hotted = pd.get_dummies(df_user_feature[field], prefix=field)\n",
    "    df_user_feature = df_user_feature.merge(hotted, how='left', left_index=True, right_index=True)\n",
    "    df_user_feature.drop(columns=[field], inplace=True)\n",
    "\n",
    "df_user_feature.to_parquet(f'{DATA_ROOT}/df_user_feature_{DNAME}.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid2law = {}\n",
    "for uid, law in df_user_feature[['last_active_week']].reset_index().values:\n",
    "    uid2law[uid] = law\n",
    "df_user_feature.drop(columns=['last_active_week'], inplace=True)\n",
    "\n",
    "with open(f'{DATA_ROOT}/uid2law_{DNAME}.pkl', 'wb') as fp:\n",
    "    pickle.dump(uid2law, fp)\n",
    "\n",
    "del uid2law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid2feature = {}\n",
    "for row in df_user_feature.reset_index().values:\n",
    "    uid = row[0]\n",
    "    feature = tuple(row[1:])\n",
    "    uid2feature[uid] = feature\n",
    "\n",
    "with open(f'{DATA_ROOT}/uid2feature_{DNAME}.pkl', 'wb') as fp:\n",
    "    pickle.dump(uid2feature, fp)\n",
    "\n",
    "del uid2feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAME = 'LB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = pd.read_parquet(f'{DATA_ROOT}/df_item_aggregated_{DNAME}.pq')\n",
    "\n",
    "df_item_feature = df_item.copy()\n",
    "\n",
    "iid2pid = {}\n",
    "iid2title = {}\n",
    "# iid2ipath = {}\n",
    "iid2desc = {}\n",
    "\n",
    "for row in df_item_feature[['product_code', 'prod_name', 'detail_desc']].itertuples():\n",
    "    iid, pid, title, desc = row\n",
    "    iid2pid[iid] = pid\n",
    "    iid2title[iid] = title\n",
    "    # iid2ipath[iid] = ipath\n",
    "    iid2desc[iid] = desc\n",
    "\n",
    "with open(f'{DATA_ROOT}/iid2pid.pkl', 'wb') as fp:\n",
    "    pickle.dump(iid2pid, fp)\n",
    "with open(f'{DATA_ROOT}/iid2title.pkl', 'wb') as fp:\n",
    "    pickle.dump(iid2title, fp)\n",
    "# with open(f'{DATA_ROOT}/iid2ipath.pkl', 'wb') as fp:\n",
    "#     pickle.dump(iid2ipath, fp)\n",
    "with open(f'{DATA_ROOT}/iid2desc.pkl', 'wb') as fp:\n",
    "    pickle.dump(iid2desc, fp)\n",
    "\n",
    "del iid2pid\n",
    "del iid2title\n",
    "# del iid2ipath\n",
    "del iid2desc\n",
    "\n",
    "df_item_feature.drop(columns=[\n",
    "    'product_code',\n",
    "    'prod_name',\n",
    "    'detail_desc',\n",
    "    'transaction_count',\n",
    "], inplace=True)\n",
    "\n",
    "one_hot_fields = [\n",
    "    'product_type_no',\n",
    "    'graphical_appearance_no',\n",
    "    'colour_group_code',\n",
    "    'perceived_colour_value_id',\n",
    "    'perceived_colour_master_id',\n",
    "    'department_no',\n",
    "    'index_code',\n",
    "    'section_no',\n",
    "    'garment_group_no',\n",
    "    'product_group_no',\n",
    "]\n",
    "\n",
    "fields_with_unknown = [\n",
    "    'product_group_no',\n",
    "    'product_type_no',\n",
    "    'graphical_appearance_no',\n",
    "    'colour_group_code',\n",
    "    'perceived_colour_value_id',\n",
    "    'perceived_colour_master_id',\n",
    "    'garment_group_no',\n",
    "]\n",
    "\n",
    "for field in one_hot_fields:\n",
    "    hotted = pd.get_dummies(df_item_feature[field], prefix=field)\n",
    "    if field in fields_with_unknown:\n",
    "        hotted = pd.get_dummies(df_item_feature[field], prefix=field)\n",
    "        unknown_field_name = f'{field}_-1'\n",
    "        unknowns_rows = (hotted[unknown_field_name] == 1)\n",
    "        hotted.loc[unknowns_rows, :] = 1 / (len(hotted.columns) - 1)\n",
    "        hotted.drop(columns=[unknown_field_name], inplace=True)\n",
    "    df_item_feature = df_item_feature.merge(hotted, how='left', left_index=True, right_index=True)\n",
    "    df_item_feature.drop(columns=[field], inplace=True)\n",
    "\n",
    "df_item_feature.to_parquet(f'{DATA_ROOT}/df_item_feature_{DNAME}.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid2feature = {}\n",
    "for row in df_item_feature.reset_index().values:\n",
    "    iid = row[0]\n",
    "    feature = tuple(row[1:])\n",
    "    iid2feature[iid] = feature\n",
    "\n",
    "del df_item_feature\n",
    "\n",
    "with open(f'{DATA_ROOT}/iid2feature_{DNAME}.pkl', 'wb') as fp:\n",
    "    pickle.dump(iid2feature, fp)\n",
    "\n",
    "del iid2feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efb881ff8f996c0b6dd8311259b4eab25403411b810201cbba5a110d03ebe070"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
